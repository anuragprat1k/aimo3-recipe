# Tinker remote training configuration
# Uses Tinker SDK to offload training to remote GPU clusters

# Model configuration
model:
  name: "Qwen/Qwen2.5-14B"
  lora_rank: 64

# Stage 1: CoT SFT via Tinker
stage1_cot:
  dataset: "AI-MO/NuminaMath-CoT"
  batch_size: 32
  num_epochs: 3
  learning_rate: null  # Auto-computed based on LoRA rank
  max_tokens: 4096
  save_every: 500
  log_dir: "./outputs/tinker_sft_cot"

# Stage 2: TIR SFT via Tinker
stage2_tir:
  dataset: "AI-MO/NuminaMath-TIR"
  batch_size: 16
  num_epochs: 2
  learning_rate: null
  max_tokens: 8192
  save_every: 200
  log_dir: "./outputs/tinker_sft_tir"

# Stage 3: RL via Tinker
# Using Big-Math RL-Verified: 250k+ verified problems designed for RL
# Reference: arXiv:2502.17387 "Big-Math" (Feb 2025)
stage3_rl:
  dataset: "SynthLabsAI/Big-Math-RL-Verified"
  batch_size: 64
  group_size: 16
  num_epochs: 1
  learning_rate: null
  max_tokens: 4096
  temperature: 0.7
  correct_reward: 1.0
  incorrect_reward: -0.5
  format_bonus: 0.1
  save_every: 100
  log_dir: "./outputs/tinker_rl_math"

# Tinker-specific settings
tinker:
  # Set TINKER_API_KEY environment variable before running
  checkpoint_resume: true
