# Tinker remote training configuration
# Uses Tinker SDK to offload training to remote GPU clusters

# Model configuration
model:
  name: "Qwen/Qwen2.5-14B"
  lora_rank: 64

# Stage 1: CoT SFT via Tinker
stage1_cot:
  dataset: "EleutherAI/hendrycks_math"
  dataset_levels: [3, 4, 5]  # Only levels 3-5 (medium to hard difficulty)
  batch_size: 32
  num_epochs: 3
  learning_rate: null  # Auto-computed based on LoRA rank
  max_tokens: 4096
  save_every: 500
  log_dir: "./outputs/tinker_sft_cot"

# Stage 2: TIR SFT via Tinker
stage2_tir:
  dataset: "EleutherAI/hendrycks_math"
  dataset_levels: [3, 4, 5]  # Only levels 3-5 (medium to hard difficulty)
  batch_size: 16
  num_epochs: 2
  learning_rate: null
  max_tokens: 8192
  save_every: 200
  log_dir: "./outputs/tinker_sft_tir"

# Stage 3: RL via Tinker
stage3_rl:
  dataset: "EleutherAI/hendrycks_math"
  dataset_levels: [3, 4, 5]  # Only levels 3-5 (medium to hard difficulty)
  batch_size: 64
  group_size: 16
  num_epochs: 1
  learning_rate: null
  max_tokens: 4096
  temperature: 0.7
  correct_reward: 1.0
  incorrect_reward: -0.5
  format_bonus: 0.1
  save_every: 100
  log_dir: "./outputs/tinker_rl_math"

# Tinker-specific settings
tinker:
  # Set TINKER_API_KEY environment variable before running
  checkpoint_resume: true
